{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\" #no annoyiing messages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we don't get any GPU errors\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data from MNIST available on tf keras datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test,y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1,28*28).astype('float32')/255.0\n",
    "x_test = x_test.reshape(-1,28*28).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we are trying to do\n",
    "We will create custom layers using subclassing like API of Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense1 = layers.Dense(64)\n",
    "        self.dense2 = layers.Dense(num_classes)\n",
    "        \n",
    "    def call(self, input_tensor):\n",
    "        x = tf.nn.relu(self.dense1(input_tensor))\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer = keras.optimizers.Adam(),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 - 2s - loss: 0.0809 - accuracy: 0.9761\n",
      "Epoch 2/3\n",
      "1875/1875 - 2s - loss: 0.0665 - accuracy: 0.9797\n",
      "Epoch 3/3\n",
      "1875/1875 - 2s - loss: 0.0562 - accuracy: 0.9826\n",
      "313/313 - 0s - loss: 0.0866 - accuracy: 0.9720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08662107586860657, 0.972000002861023]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train, epochs = 3, batch_size=32, verbose=2)\n",
    "model.evaluate(x_test, y_test, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will create our Dense layer by ourselves  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(layers.Layer):\n",
    "    def __init__(self, units, input_dim):\n",
    "        super(Dense,self).__init__()\n",
    "        #now, we will add weights\n",
    "        self.w = self.add_weight(\n",
    "            name='w',\n",
    "            shape=(input_dim,units),\n",
    "            initializer='random_normal',\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        #add bias\n",
    "        self.b = self.add_weight(\n",
    "            name='b', shape = (units,), initializer ='zeros', trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # we will perform the basic operation of a  neutral net, W.X + b and return\n",
    "        return tf.matmul(inputs,self.w) + self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will remake mymodel with OWN dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 - 1s - loss: 0.3519 - accuracy: 0.9036\n",
      "Epoch 2/3\n",
      "1875/1875 - 1s - loss: 0.1664 - accuracy: 0.9514\n",
      "Epoch 3/3\n",
      "1875/1875 - 1s - loss: 0.1151 - accuracy: 0.9662\n",
      "313/313 - 0s - loss: 0.1118 - accuracy: 0.9663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11184829473495483, 0.9663000106811523]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyModel_withDense(keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel_withDense, self).__init__()\n",
    "        self.dense1 = Dense(units = 64, input_dim = 28*28)\n",
    "        self.dense2 = Dense(units = 10, input_dim = 64)\n",
    "        \n",
    "    def call(self, input_tensor):\n",
    "        x = tf.nn.relu(self.dense1(input_tensor))\n",
    "        return self.dense2(x)\n",
    "    \n",
    "model = MyModel_withDense()\n",
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer = keras.optimizers.Adam(),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(x_train,y_train, epochs = 3, batch_size=32, verbose=2)\n",
    "model.evaluate(x_test, y_test, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works!\n",
    "But there is still something, We have to specify the input dimension for each Dense layer. We will now make it so that this is worked out by the Dense Layer itself. We will also implement the Relu Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRelu(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MyRelu, self).__init__()\n",
    "        \n",
    "    def call(self,x):\n",
    "        return tf.math.maximum(x,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense_Lazy(layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(Dense_Lazy,self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # we will make the weights here only\n",
    "        self.w = self.add_weight(\n",
    "            name='w',\n",
    "            shape=(input_shape[-1],self.units),\n",
    "            initializer='random_normal',\n",
    "            trainable=True\n",
    "        )\n",
    "        #add bias\n",
    "        self.b = self.add_weight(\n",
    "            name='b', shape = (self.units,), initializer ='zeros', trainable=True\n",
    "        )\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # we will perform the basic operation of a  neutral net, W.X + b and return\n",
    "        return tf.matmul(inputs,self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 - 2s - loss: 0.3393 - accuracy: 0.9076\n",
      "Epoch 2/3\n",
      "1875/1875 - 2s - loss: 0.1605 - accuracy: 0.9534\n",
      "Epoch 3/3\n",
      "1875/1875 - 2s - loss: 0.1170 - accuracy: 0.9657\n",
      "313/313 - 0s - loss: 0.1083 - accuracy: 0.9684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10829201340675354, 0.9684000015258789]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyModel_withDense(keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel_withDense, self).__init__()\n",
    "        self.dense1 = Dense_Lazy(64)\n",
    "        self.dense2 = Dense_Lazy(10)\n",
    "        self.relu = MyRelu()\n",
    "        \n",
    "    def call(self, input_tensor):\n",
    "        x = self.relu(self.dense1(input_tensor))\n",
    "        return self.dense2(x)\n",
    "\n",
    "model = MyModel_withDense()\n",
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer = keras.optimizers.Adam(),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(x_train,y_train, epochs = 3, batch_size=32, verbose=2)\n",
    "model.evaluate(x_test, y_test, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu]",
   "language": "python",
   "name": "conda-env-tf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
