{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Will use Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### MNIST form tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train,ds_test), ds_info = tfds.load(\n",
    "    \"mnist\",\n",
    "    split = ['train','test'],\n",
    "    shuffle_files= True,\n",
    "    as_supervised = True, #tuple of img,label\n",
    "    with_info = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image,label):\n",
    "    #normalize images\n",
    "    return tf.cast(image, tf.float32)/255.0 , label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE #to autotune hyperparameters where it is called\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls = AUTOTUNE) #applies function to call images, labels\n",
    "ds_train = ds_train.cache() #\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(BATCH_SIZE)\n",
    "ds_train = ds_train.prefetch(AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(normalize_img, num_parallel_calls = AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input((28,28,1)),\n",
    "    layers.Conv2D(32,3,activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(ds_train, epochs=20, verbose=2)\n",
    "model.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train,ds_test), ds_info = tfds.load(\n",
    "    \"imdb_reviews\",\n",
    "    split = ['train','test'],\n",
    "    shuffle_files= True,\n",
    "    as_supervised = True, #tuple of img,label\n",
    "    with_info = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.features.text.Tokenizer() #text tokenizer\n",
    "\n",
    "def build_vocabulary():\n",
    "    vocabulary = set()\n",
    "    for text, _ in ds_train:\n",
    "        vocabulary.update(tokenizer.tokenize(text.numpy().lower())) #add all words to vocab\n",
    "    return vocabulary\n",
    "\n",
    "vocabulary = build_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tfds.features.text.TokenTextEncoder(\n",
    "    vocabulary, oov_token = \"<UNK>\" , lowercase = True, tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "def encoding_fn(text_tensor, label):\n",
    "    return encoder.encode(text_tensor.numpy()), label\n",
    "\n",
    "def encode_map(text, label):\n",
    "    #specifiy the i/o of above function\n",
    "    encoded_text, label = tf.py_function(\n",
    "        encoding_fn, inp = [text, label], Tout = (tf.int64, tf.int64)\n",
    "    )\n",
    "    \n",
    "    encoded_text.set_shape([None])\n",
    "    label.set_shape([])\n",
    "    \n",
    "    return encoded_text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "ds_train = ds_train.map(encode_map, num_parallel_calls = AUTOTUNE).cache()\n",
    "ds_train = ds_train.shuffle(10000)\n",
    "ds_train = ds_train.padded_batch(32, padded_shapes=([None],()))\n",
    "ds_train = ds_train.prefetch(AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(encode_map)\n",
    "ds_test = ds_test.padded_batch(32, padded_shapes=([None],()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 - 18s - loss: 0.6758 - accuracy: 0.5058\n",
      "Epoch 2/10\n",
      "782/782 - 16s - loss: 0.5016 - accuracy: 0.7187\n",
      "Epoch 3/10\n",
      "782/782 - 16s - loss: 0.3420 - accuracy: 0.8566\n",
      "Epoch 4/10\n",
      "782/782 - 17s - loss: 0.2733 - accuracy: 0.8914\n",
      "Epoch 5/10\n",
      "782/782 - 16s - loss: 0.2322 - accuracy: 0.9110\n",
      "Epoch 6/10\n",
      "782/782 - 17s - loss: 0.2030 - accuracy: 0.9234\n",
      "Epoch 7/10\n",
      "782/782 - 16s - loss: 0.1793 - accuracy: 0.9350\n",
      "Epoch 8/10\n",
      "782/782 - 18s - loss: 0.1591 - accuracy: 0.9431\n",
      "Epoch 9/10\n",
      "782/782 - 17s - loss: 0.1421 - accuracy: 0.9505\n",
      "Epoch 10/10\n",
      "782/782 - 18s - loss: 0.1270 - accuracy: 0.9571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f91883f8d60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Masking(mask_value = 0), #ignore the values with padded 0s\n",
    "        layers.Embedding(input_dim=len(vocabulary) +2, output_dim = 32),\n",
    "        \n",
    "        #Batchsize x 100 x32 is given. out\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        \n",
    "        # now is Batchsize x 32 (taking avg)\n",
    "        layers.Dense(64, activation = 'relu'),\n",
    "        layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer = keras.optimizers.Adam(3e-4,clipnorm=1),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(ds_train, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 11s 14ms/step - loss: 0.2925 - accuracy: 0.8908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29252007603645325, 0.8908399939537048]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu]",
   "language": "python",
   "name": "conda-env-tf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
