{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import torch #main torch module\n",
    "import torch.nn as nn #neural net module\n",
    "import torch.optim as optim #optimizers\n",
    "import torch.nn.functional as F #functions like ReLu Sig Tanh etc\n",
    "from torch.utils.data import DataLoader #help us with datasets\n",
    "\n",
    "import torchvision.datasets as datasets #using to access std data\n",
    "import torchvision.transforms as transforms #transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Network Definition\n",
    "We will define our RNN here.  \n",
    "Now we will use the RNN with Images.  \n",
    "Image has 28x28x1 dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We dont use RNNs for Images, but in this case we can imagine  \n",
    "as there are 28 time steps in this RNN, and we will send the   image row by row into the RNN. Each row is 28 that will go  \n",
    "So we will use, different hyperparameters, as given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "input_size = 28\n",
    "sequence_length = 28\n",
    "num_layers = 2\n",
    "hidden_size = 256\n",
    "num_classes = 10\n",
    "learning_rate =  0.001\n",
    "batch_size = 64\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Now we will define RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first = True)\n",
    "        #No of sequences is not necessary, works for any number\n",
    "        #batch first\n",
    "        self.fc = nn.Linear(hidden_size*sequence_length, num_classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        #forward prop\n",
    "        out, _ = self.rnn(x,h0)\n",
    "        out = out.reshape(out.shape[0],-1)\n",
    "        out = self.fc(out)\n",
    "        #keeping batch as first axis, flatten rest\n",
    "        return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### Modelling and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Set Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "train_dataset = datasets.MNIST(root='dataset/',\n",
    "                               train=True, \n",
    "                               transform = transforms.ToTensor(),\n",
    "                               download = True)\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset,\n",
    "                         batch_size = batch_size,\n",
    "                         shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Loading Test Data\n",
    "test_dataset = datasets.MNIST(root='dataset/',\n",
    "                               train=False, \n",
    "                               transform = transforms.ToTensor(),\n",
    "                               download = True)\n",
    "\n",
    "test_loader = DataLoader(dataset = test_dataset,\n",
    "                         batch_size = batch_size,\n",
    "                         shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#init the network\n",
    "\n",
    "model = NN(input_size,\n",
    "          num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                      lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx,(data, targets) in enumerate(train_loader):\n",
    "        # data to devices\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        data = data.reshape(data.shape[0],-1)#flattens\n",
    "        \n",
    "        #fwd\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        \n",
    "        #back\n",
    "        optimizer.zero_grad() #so that it does not store prev backprop calc\n",
    "        loss.backward()\n",
    "        \n",
    "        #gradient desc\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def check_accuracy(loader,model):\n",
    "    if loader.dataset.train:\n",
    "        print(\"Checking Training Data Accuracy\")\n",
    "    else:\n",
    "        print(\"Checking Test Data Accuract\")\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() #set to evaluation mode\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        #only have to check accuracy, dont compute grads\n",
    "        for x,y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            x = x.reshape(x.shape[0],-1)\n",
    "            \n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            \n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "        accuracy = float(num_correct)/float(num_samples)*100\n",
    "        print(f\"Got {num_correct} / {num_samples} with accuracy {accuracy: .2f}\")\n",
    "\n",
    "    model.train()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "check_accuracy(test_loader,model)\n",
    "check_accuracy(train_loader,model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch-gpu]",
   "language": "python",
   "name": "conda-env-torch-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
